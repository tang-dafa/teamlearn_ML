{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "1.概念\n",
    "\t生成模型\n",
    "\t\t在概率统计理论中, 生成模型是指能够随机生成观测数据的模型，尤其是在给定某些隐含参数的条件下\n",
    "\t\t用法：在机器学习中，生成模型可以用来直接对数据建模（例如根据某个变量的概率密度函数进行数据采样），也可以用来建立变量间的条件概率分布。条件概率分布可以由生成模型根据贝叶斯定理形成。\n",
    "\t\t常见的基于生成模型算法\n",
    "\t\t\t高斯混合模型和其他混合模型\n",
    "\t\t\t隐马尔可夫模型\n",
    "\t\t\t随机上下文无关文法\n",
    "\t\t\t朴素贝叶斯分类器\n",
    "\t\t\tAODE分类器\n",
    "\t\t\t潜在狄利克雷分配模型\n",
    "\t\t\t受限玻尔兹曼机\n",
    "\t判别模型\n",
    "\t\t在机器学习领域判别模型是一种对未知数据 y 与已知数据 x 之间关系进行建模的方法。判别模型是一种基于概率理论的方法。已知输入变量 x ，判别模型通过构建条件概率分布 P(y|x) 预测 y 。\n",
    "\t\t基于判别模型算法\n",
    "\t\t\t逻辑回归\n",
    "\t\t\t线性回归\n",
    "\t\t\t支持向量机\n",
    "\t\t\t提升方法\n",
    "\t\t\t条件随机场\n",
    "\t\t\t人工神经网络\n",
    "\t\t\t随机森林\n",
    "\t\t\t感知器\n",
    "\t区别：\n",
    "\t\t生成模型是所有变量的全概率模型，而判别模型是在给定观测变量值前提下目标变量条件概率模型。因此生成模型能够用于模拟（即生成）模型中任意变量的分布情况，而判别模型只能根据观测变量得到目标变量的采样。\n",
    "\t\t判别模型不对观测变量的分布建模，因此它不能够表达观测变量与目标变量之间更复杂的关系。因此，生成模型更适用于无监督的任务，如分类和聚类。\n",
    "\t\t举例：利用生成模型是根据好瓜的特征首先学习出一个好瓜的模型，然后根据坏瓜的特征学习得到一个坏瓜的模型，然后从需要预测的瓜中提取特征，放到生成好的好瓜的模型中看概率是多少，在放到生产的坏瓜模型中看概率是多少，哪个概率大就预测其为哪个。\n",
    "\n",
    "2.先验概率和条件概率\n",
    "\t条件概率：就是事件A在事件B发生的条件下发生的概率。条件概率表示为P（A|B），读作“A在B发生的条件下发生的概率”。\n",
    "\t先验概率：在贝叶斯统计中，某一不确定量 p 的先验概率分布是在考虑\"观测数据\"前，能表达 p 不确定性的概率分布。它旨在描述这个不确定量的不确定程度，而不是这个不确定量的随机性。这个不确定量可以是一个参数，或者是一个隐含变量。\n",
    "\t后验概率：在贝叶斯统计中，一个随机事件或者一个不确定事件的后验概率是在考虑和给出相关证据或数据后所得到的条件概率。同样，后验概率分布是一个未知量（视为随机变量）基于试验和调查后得到的概率分布。“后验”在本文中代表考虑了被测试事件的相关证据。\n",
    "\t举例：\n",
    "\t\t条件概率，就是在条件为瓜的颜色是青绿的情况下，瓜是好瓜的概率\n",
    "\t\t先验概率，就是常识、经验、统计学所透露出的“因”的概率，即瓜的颜色是青绿的概率\n",
    "\t\t后验概率，就是在知道“果”之后，去推测“因”的概率，也就是说，如果已经知道瓜是好瓜，那么瓜的颜色是青绿的概率是多少。后验和先验的关系就需要运用贝叶斯决策理论来求解。\n",
    "\n",
    "3.贝叶斯决策理论\n",
    "\t贝叶斯决策论是概率框架下实施决策的基本方法，对分类任务来说，在所有相关概率都已知的理想情形下，贝叶斯决策论考虑如何基于这些概率和误判损失来选择最优的类别标记。\n",
    "\n",
    "4.贝叶斯公式\n",
    "\t公式\n",
    "\t极大似然估计：最大似然估计的过程，就是找一个合适的theta，使得平均对数似然的值为最大\n",
    "\t\t需要注意的是这种方法虽然能够使类条件概率估计变得简单，但是估计结果准确性严重依赖于所假设的概率分布形式是否符合潜在的真实数据分布。在显示生活中往往需要应用任务本身的经验知识，“猜测”则会导致误导性的结果。\n",
    "\t\t贝叶斯分类器的训练过程就是参数估计。总结最大似然法估计参数的过程，一般分为以下四个步骤：\n",
    "\t\t\t写出似然函数\n",
    "\t\t\t对似然函数取对数，并整理\n",
    "\t\t\t求导数，令偏导数为0，得到似然方程组\n",
    "\t\t\t解似然方程组，得到所有参数即为所求\n",
    "\t朴素贝叶斯分类器\n",
    "\t\t基于贝叶斯公式来估计后验概率P(c|x)主要困难在于类条件概率P(x|c)是所有属性上的联合概率，难以从有限的训练样本直接估计而得。 基于有限训练样本直接计算联合概率，在计算上将会遭遇组合爆炸问题；在数据上将会遭遇样本稀疏问题；属性越多，问题越严重。\n",
    "\t\t为了避开这个障碍，朴素贝叶斯分类器采用了 “属性条件独立性假设” :对已知类别，假设所有属性相互独立。换言之，假设每个属性独立的对分类结果发生影响相互独立。（回答西瓜的例子就可以认为｛色泽 根蒂 敲声 纹理 脐部 触感｝这些属性对西瓜是好还是坏的结果所产生的影响相互独立。）\n",
    "\n",
    "5.极值问题情况下的每个类的分类概率\n",
    "\t很多时候遇到求出各种目标函数（object function）的最值问题（最大值或者最小值）。关于函数最值问题，其实在高中的时候我们就已经了解不少，最经典的方法就是：直接求出极值点。这些极值点的梯度为0。若极值点唯一，则这个点就是代入函数得出的就是最值；若极值点不唯一，那么这些点中，必定存在最小值或者最大值（去除函数的左右的最端点），所以把极值代入函数，经对比后可得到结果。\n",
    "    请注意：并不一定所有函数的极值都可以通过设置导数为0的方式求 出。也就是说，有些问题中当我们设定导数为0时，未必能直接计算出满足导数为0的点（比如逻辑回归模型），这时候就需要利用数值计算相关的技术（最典型为梯度下降法，牛顿法……）。\n",
    "\n",
    "6.下溢问题如何解决\n",
    "\t数值下溢问题：是指计算机浮点数计算的结果小于可以表示的最小数，因为计算机的能力有限，当数值小于一定数时，其无法精确保存，会造成数值的精度丢失\n",
    "\t由上述公式可以看到，求概率时多个概率值相乘，得到的结果往往非常小；因此通常采用取对数的方式，将连乘转化为连加，以避免数值下溢。\n",
    "\n",
    "7.零概率问题如何解决\n",
    "\t在计算实例的概率时，如果某个量x，在观察样本库（训练集）中没有出现过，会导致整个实例的概率结果是0.\n",
    "\t\t在实际的模型训练过程中，可能会出现零概率问题（因为先验概率和反条件概率是根据训练样本算的，但训练样本数量不是无限的，所以可能出现有的情况在实际中存在，但在训练样本中没有，导致为0的概率值，影响后面后验概率的计算），即便可以继续增加训练数据量，但对于有些问题来说，数据怎么增多也是不够的。这时我们说模型是不平滑的，我们要使之平滑，一种方法就是将训练（学习）的方法换成贝叶斯估计。\n",
    "\n",
    "8.sklearn参数\n",
    "    高斯朴素贝叶斯算法是假设特征的可能性为高斯分布\n",
    "        sklearn.navie_bayes.GaussianNB(proors = None)\n",
    "        参数：\n",
    "        priors : 先验概率的大小，如果没有给，模型则根据样本数据自己算（使用的是极大似然法）\n",
    "        var_smoothing:可选参数，所有特征的最大方差\n",
    "        属性：\n",
    "        class_prior_ :每个样本的概率\n",
    "        class_count : 每个类别的样本数量\n",
    "        classes_ : 分类器已知的标签类型\n",
    "        theta_ : 每个类别中每个特征的均值\n",
    "        sigma_: 每个类别中每个特征的方差\n",
    "        epsilon_ : 方差的绝对加值方法\n",
    "        # 实例\n",
    "        fit(X,Y):在数据集(X,Y)上拟合模型。\n",
    "        get_params():获取模型参数。\n",
    "        predict(X):对数据集X进行预测。\n",
    "        predict_log_proba(X):对数据集X预测，得到每个类别的概率对数值。\n",
    "        predict_proba(X):对数据集X预测，得到每个类别的概率。\n",
    "        score(X,Y):得到模型在数据集(X,Y)的得分情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Score: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# 导入\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris = load_iris()\n",
    "X_train,X_test,y_train,y_test = train_test_split(iris.data , iris.target,test_size=0.2)\n",
    "clf = GaussianNB().fit(X_train,y_train)\n",
    "print(\"Classifier Score:\" , clf.score(X_test , y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import math\n",
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    # 数学期望\n",
    "    @staticmethod\n",
    "    def mean(X):\n",
    "        \"\"\"计算均值\n",
    "        Param: X : list or np.ndarray\n",
    "        \n",
    "        Return:\n",
    "            avg : float\n",
    "        \n",
    "        \"\"\"\n",
    "        avg = 0.0\n",
    "\n",
    "        avg = sum(X) / float(len(X))\n",
    "\n",
    "        return avg\n",
    "\n",
    "    # 标准差（方差）\n",
    "    def stdev(self, X):\n",
    "        \"\"\"计算标准差\n",
    "        Param: X : list or np.ndarray\n",
    "        \n",
    "        Return:\n",
    "            res : float\n",
    "        \n",
    "        \"\"\"\n",
    "        res = 0.0\n",
    "\n",
    "        avg = self.mean(X)\n",
    "        res = math.sqrt(sum([pow(x - avg, 2) for x in X]) / float(len(X)))\n",
    "\n",
    "        return res\n",
    "        \n",
    "    # 概率密度函数\n",
    "    def gaussian_probability(self, x, mean, stdev):\n",
    "        \"\"\"根据均值和标注差计算x符号该高斯分布的概率\n",
    "        Parameters:\n",
    "        ----------\n",
    "        x : 输入\n",
    "        mean : 均值\n",
    "        stdev : 标准差\n",
    "        \n",
    "        Return:\n",
    "        \n",
    "        res : float， x符合的概率值\n",
    "            \n",
    "        \"\"\"\n",
    "        res = 0.0\n",
    "\n",
    "        exponent = math.exp(-(math.pow(x - mean, 2) /\n",
    "                              (2 * math.pow(stdev, 2))))\n",
    "        res = (1 / (math.sqrt(2 * math.pi) * stdev)) * exponent\n",
    "\n",
    "        \n",
    "        return res\n",
    "        \n",
    "    # 处理X_train\n",
    "    def summarize(self, train_data):\n",
    "        \"\"\"计算每个类目下对应数据的均值和标准差\n",
    "        Param: train_data : list\n",
    "        \n",
    "        Return : [mean, stdev]\n",
    "        \"\"\"\n",
    "        summaries = [0.0, 0.0]\n",
    "\n",
    "        summaries = [(self.mean(i), self.stdev(i)) for i in zip(*train_data)]\n",
    "\n",
    "        return summaries\n",
    "\n",
    "    # 分类别求出数学期望和标准差\n",
    "    def fit(self, X, y):\n",
    "        labels = list(set(y))\n",
    "        data = {label: [] for label in labels}\n",
    "        for f, label in zip(X, y):\n",
    "            data[label].append(f)\n",
    "        self.model = {\n",
    "            label: self.summarize(value) for label, value in data.items()\n",
    "        }\n",
    "        return 'gaussianNB train done!'\n",
    "\n",
    "    # 计算概率\n",
    "    def calculate_probabilities(self, input_data):\n",
    "        \"\"\"计算数据在各个高斯分布下的概率\n",
    "        Paramter:\n",
    "        input_data : 输入数据\n",
    "        \n",
    "        Return:\n",
    "        probabilities : {label : p}\n",
    "        \"\"\"\n",
    "        probabilities = {}\n",
    "\n",
    "        for label, value in self.model.items():\n",
    "            probabilities[label] = 1\n",
    "            for i in range(len(value)):\n",
    "                mean, stdev = value[i]\n",
    "                probabilities[label] *= self.gaussian_probability(\n",
    "                    input_data[i], mean, stdev)\n",
    "\n",
    "        return probabilities\n",
    "\n",
    "    # 类别\n",
    "    def predict(self, X_test):\n",
    "        # {0.0: 2.9680340789325763e-27, 1.0: 3.5749783019849535e-26}\n",
    "        label = sorted(self.calculate_probabilities(X_test).items(), key=lambda x: x[-1])[-1][0]\n",
    "        return label\n",
    "    # 计算得分\n",
    "    def score(self, X_test, y_test):\n",
    "        right = 0\n",
    "        for X, y in zip(X_test, y_test):\n",
    "            label = self.predict(X)\n",
    "            if label == y:\n",
    "                right += 1\n",
    "\n",
    "        return right / float(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gaussianNB train done!'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_test , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([4.4,3.2,1.4,0.2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test , y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
